{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jB7Zk_RtiHB9"
   },
   "outputs": [],
   "source": [
    "workdir = \"/Users/leon/workdir/ml-learning-projects/hw3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocV8wjSLkbWd"
   },
   "source": [
    "# Preprocess Lofi music into Numpy Array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PRU9hYhY1OlE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import math\n",
    "import threading\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import librosa as lr\n",
    "import bisect\n",
    "\n",
    "\n",
    "class WavenetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 dataset_file,\n",
    "                 item_length,\n",
    "                 target_length,\n",
    "                 file_location=None,\n",
    "                 classes=256,\n",
    "                 sampling_rate=16000,\n",
    "                 mono=True,\n",
    "                 normalize=False,\n",
    "                 dtype=np.uint8,\n",
    "                 train=True,\n",
    "                 test_stride=100):\n",
    "\n",
    "        #           |----receptive_field----|\n",
    "        #                                 |--output_length--|\n",
    "        # example:  | | | | | | | | | | | | | | | | | | | | |\n",
    "        # target:                           | | | | | | | | | |\n",
    "\n",
    "        self.dataset_file = dataset_file\n",
    "        self._item_length = item_length\n",
    "        self._test_stride = test_stride\n",
    "        self.target_length = target_length\n",
    "        self.classes = classes\n",
    "\n",
    "        if not os.path.isfile(dataset_file):\n",
    "            assert file_location is not None, \"no location for dataset files specified\"\n",
    "            self.mono = mono\n",
    "            self.normalize = normalize\n",
    "\n",
    "            self.sampling_rate = sampling_rate\n",
    "            self.dtype = dtype\n",
    "            self.create_dataset(file_location, dataset_file)\n",
    "        else:\n",
    "            # Unknown parameters of the stored dataset\n",
    "            # TODO Can these parameters be stored, too?\n",
    "            self.mono = None\n",
    "            self.normalize = None\n",
    "\n",
    "            self.sampling_rate = None\n",
    "            self.dtype = None\n",
    "\n",
    "        self.data = np.load(self.dataset_file, mmap_mode='r')\n",
    "        self.start_samples = [0]\n",
    "        self._length = 0\n",
    "        self.calculate_length()\n",
    "        self.train = train\n",
    "        print(\"one hot input\")\n",
    "        # assign every *test_stride*th item to the test set\n",
    "\n",
    "    def create_dataset(self, location, out_file):\n",
    "        print(\"create dataset from audio files at\", location)\n",
    "        self.dataset_file = out_file\n",
    "        files = list_all_audio_files(location)\n",
    "        processed_files = []\n",
    "        for i, file in enumerate(files):\n",
    "            print(\"  processed \" + str(i) + \" of \" + str(len(files)) + \" files\")\n",
    "            file_data, _ = lr.load(path=file,\n",
    "                                   sr=self.sampling_rate,\n",
    "                                   mono=self.mono)\n",
    "            if self.normalize:\n",
    "                file_data = lr.util.normalize(file_data)\n",
    "            quantized_data = quantize_data(file_data, self.classes).astype(self.dtype)\n",
    "            processed_files.append(quantized_data)\n",
    "\n",
    "        np.savez(self.dataset_file, *processed_files)\n",
    "\n",
    "    def calculate_length(self):\n",
    "        start_samples = [0]\n",
    "        for i in range(len(self.data.keys())):\n",
    "            start_samples.append(start_samples[-1] + len(self.data['arr_' + str(i)]))\n",
    "        available_length = start_samples[-1] - (self._item_length - (self.target_length - 1)) - 1\n",
    "        self._length = math.floor(available_length / self.target_length)\n",
    "        self.start_samples = start_samples\n",
    "\n",
    "    def set_item_length(self, l):\n",
    "        self._item_length = l\n",
    "        self.calculate_length()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self._test_stride < 2:\n",
    "            sample_index = idx * self.target_length\n",
    "        elif self.train:\n",
    "            sample_index = idx * self.target_length + math.floor(idx / (self._test_stride-1))\n",
    "        else:\n",
    "            sample_index = self._test_stride * (idx+1) - 1\n",
    "\n",
    "        file_index = bisect.bisect_left(self.start_samples, sample_index) - 1\n",
    "        if file_index < 0:\n",
    "            file_index = 0\n",
    "        if file_index + 1 >= len(self.start_samples):\n",
    "            print(\"error: sample index \" + str(sample_index) + \" is to high. Results in file_index \" + str(file_index))\n",
    "        position_in_file = sample_index - self.start_samples[file_index]\n",
    "        end_position_in_next_file = sample_index + self._item_length + 1 - self.start_samples[file_index + 1]\n",
    "\n",
    "        if end_position_in_next_file < 0:\n",
    "            file_name = 'arr_' + str(file_index)\n",
    "            this_file = np.load(self.dataset_file, mmap_mode='r')[file_name]\n",
    "            sample = this_file[position_in_file:position_in_file + self._item_length + 1]\n",
    "        else:\n",
    "            # load from two files\n",
    "            file1 = np.load(self.dataset_file, mmap_mode='r')['arr_' + str(file_index)]\n",
    "            file2 = np.load(self.dataset_file, mmap_mode='r')['arr_' + str(file_index + 1)]\n",
    "            sample1 = file1[position_in_file:]\n",
    "            sample2 = file2[:end_position_in_next_file]\n",
    "            sample = np.concatenate((sample1, sample2))\n",
    "\n",
    "        example = torch.from_numpy(sample).type(torch.LongTensor)\n",
    "        one_hot = torch.FloatTensor(self.classes, self._item_length).zero_()\n",
    "        one_hot.scatter_(0, example[:self._item_length].unsqueeze(0), 1.)\n",
    "        target = example[-self.target_length:].unsqueeze(0)\n",
    "        return one_hot, target\n",
    "\n",
    "    def __len__(self):\n",
    "        test_length = math.floor(self._length / self._test_stride)\n",
    "        if self.train:\n",
    "            return self._length - test_length\n",
    "        else:\n",
    "            return test_length\n",
    "\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    bins = np.linspace(-1, 1, classes)\n",
    "    quantized = np.digitize(mu_x, bins) - 1\n",
    "    return quantized\n",
    "\n",
    "\n",
    "def list_all_audio_files(location):\n",
    "    audio_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(location):\n",
    "        for filename in [f for f in filenames if f.endswith((\".mp3\", \".wav\", \".aif\", \"aiff\"))]:\n",
    "            audio_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "    if len(audio_files) == 0:\n",
    "        print(\"found no audio files in \" + location)\n",
    "    return audio_files\n",
    "\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em-B_FZ5muyX"
   },
   "source": [
    "# WaveNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OTwv8x6pUX9T"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_JvZuZ0Umv4r"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class DilatedCausalConv1d(torch.nn.Module):\n",
    "    \"\"\"Dilated Causal Convolution for WaveNet\"\"\"\n",
    "    def __init__(self, channels, dilation=1):\n",
    "        super(DilatedCausalConv1d, self).__init__()\n",
    "\n",
    "        self.conv1d = torch.nn.Conv1d(channels, channels,\n",
    "                                    kernel_size=2, stride=1,  # Fixed for WaveNet\n",
    "                                    dilation=dilation,\n",
    "                                    padding=0,  # Fixed for WaveNet dilation\n",
    "                                    bias=False)  # Fixed for WaveNet but not sure\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1d(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CausalConv1d(torch.nn.Module):\n",
    "    \"\"\"Causal Convolution for WaveNet\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                    kernel_size=2, stride=1, padding=1,\n",
    "                                    bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv(x)\n",
    "\n",
    "        # remove last value for causal convolution\n",
    "        return output[:, :, :-1]\n",
    "\n",
    "\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, res_channels, skip_channels, dilation):\n",
    "        \"\"\"\n",
    "        Residual block\n",
    "        :param res_channels: number of residual channel for input, output\n",
    "        :param skip_channels: number of skip channel for output\n",
    "        :param dilation:\n",
    "        \"\"\"\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.dilated = DilatedCausalConv1d(res_channels, dilation=dilation)\n",
    "        self.conv_res = torch.nn.Conv1d(res_channels, res_channels, 1)\n",
    "        self.conv_skip = torch.nn.Conv1d(res_channels, skip_channels, 1)\n",
    "\n",
    "        self.gate_tanh = torch.nn.Tanh()\n",
    "        self.gate_sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, skip_size):\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :param skip_size: The last output size for loss and prediction\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        output = self.dilated(x)\n",
    "\n",
    "        # PixelCNN gate\n",
    "        gated_tanh = self.gate_tanh(output)\n",
    "        gated_sigmoid = self.gate_sigmoid(output)\n",
    "        gated = gated_tanh * gated_sigmoid\n",
    "\n",
    "        # Residual network\n",
    "        output = self.conv_res(gated)\n",
    "        input_cut = x[:, :, -output.size(2):]\n",
    "        output += input_cut\n",
    "\n",
    "        # Skip connection\n",
    "        skip = self.conv_skip(gated)\n",
    "        skip = skip[:, :, -skip_size:]\n",
    "\n",
    "        return output, skip\n",
    "\n",
    "\n",
    "class ResidualStack(torch.nn.Module):\n",
    "    def __init__(self, layer_size, stack_size, res_channels, skip_channels):\n",
    "        \"\"\"\n",
    "        Stack residual blocks by layer and stack size\n",
    "        :param layer_size: integer, 10 = layer[dilation=1, dilation=2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "        :param stack_size: integer, 5 = stack[layer1, layer2, layer3, layer4, layer5]\n",
    "        :param res_channels: number of residual channel for input, output\n",
    "        :param skip_channels: number of skip channel for output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(ResidualStack, self).__init__()\n",
    "\n",
    "        self.layer_size = layer_size\n",
    "        self.stack_size = stack_size\n",
    "        # 5 = stack[layer1, layer2, layer3, layer4, layer5]\n",
    "        # 10 = layer[dilation=1, dilation=2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "        self.res_blocks = [self._residual_block(res_channels, skip_channels, 2**l) for s in range(0, self.stack_size) for l in range(0, self.layer_size)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _residual_block(res_channels, skip_channels, dilation):\n",
    "        block = ResidualBlock(res_channels, skip_channels, dilation)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            block.cuda()\n",
    "\n",
    "        return block\n",
    "\n",
    "    def forward(self, x, skip_size):\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :param skip_size: The last output size for loss and prediction\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        output = x\n",
    "        skip_connections = []\n",
    "\n",
    "        for res_block in self.res_blocks:\n",
    "            # output is the next input\n",
    "            output, skip = res_block(output, skip_size)\n",
    "            skip_connections.append(skip)\n",
    "\n",
    "        return torch.stack(skip_connections)\n",
    "\n",
    "\n",
    "class DenseNet(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        The last network of WaveNet\n",
    "        :param channels: number of channels for input and output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(channels, channels, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(channels, channels, 1)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.relu(x)\n",
    "        output = self.conv1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.conv2(output)\n",
    "\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zUWxyHq_jN1e"
   },
   "outputs": [],
   "source": [
    "class WaveNet(torch.nn.Module):\n",
    "    def __init__(self, layer_size, block_size, in_channels, res_channels):\n",
    "        \"\"\"\n",
    "        Stack residual blocks by layer and stack size\n",
    "        :param layer_size: integer, 10 = layer[dilation=1, dilation=2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "        :param stack_size: integer, 5 = stack[layer1, layer2, layer3, layer4, layer5]\n",
    "        :param in_channels: number of channels for input data. skip channel is same as input channel\n",
    "        :param res_channels: number of residual channel for input, output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(WaveNet, self).__init__()\n",
    "\n",
    "        self.receptive_fields = self.calc_receptive_fields(layer_size, block_size)\n",
    "\n",
    "        self.causal = CausalConv1d(in_channels, res_channels)\n",
    "\n",
    "        self.res_block = ResidualStack(layer_size, block_size, res_channels, in_channels)\n",
    "\n",
    "        self.densenet = DenseNet(in_channels)\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_receptive_fields(layer_size, block_size):\n",
    "        layers = [2 ** i for i in range(0, layer_size)] * block_size\n",
    "        num_receptive_fields = np.sum(layers)\n",
    "\n",
    "        return int(num_receptive_fields)\n",
    "\n",
    "    def calc_output_size(self, x):\n",
    "        # B, L, C\n",
    "        output_size = int(x.size(2)) - self.receptive_fields\n",
    "\n",
    "        #self.check_input_size(x, output_size)\n",
    "\n",
    "        return output_size\n",
    "\n",
    "    # def check_input_size(self, x, output_size):\n",
    "    #     if output_size < 1:\n",
    "    #         raise InputSizeError(int(x.size(2)), self.receptive_fields, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The size of timestep(3rd dimention) has to be bigger than receptive fields\n",
    "        :param x: Tensor[batch, timestep, channels]\n",
    "        :return: Tensor[batch, timestep, channels]\n",
    "        \"\"\"\n",
    "        output = x.transpose(1, 2)\n",
    "\n",
    "        output_size = self.calc_output_size(output)\n",
    "\n",
    "        output = self.causal(output)\n",
    "\n",
    "        skip_connections = self.res_block(output, output_size)\n",
    "\n",
    "        output = torch.sum(skip_connections, dim=0)\n",
    "\n",
    "        output = self.densenet(output)\n",
    "\n",
    "        return output.transpose(1, 2).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6f9jYU504cM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i__yewTo07UF"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Kt22CZF08Hd",
    "outputId": "27f43cc1-6a6e-4706-e0a7-34e360747363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "one hot input\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from types import SimpleNamespace\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.net = WaveNet(config.layer_size, config.stack_size, config.in_channels, config.res_channels)\n",
    "\n",
    "        self.in_channels = config.in_channels\n",
    "        self.receptive_fields = self.net.receptive_fields\n",
    "        self.output_length = 16\n",
    "        self.lr = config.lr\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        print(config.sample_size)\n",
    "        # self.data_loader = DataLoader(config.data_dir, self.receptive_fields,\n",
    "        #                               sample_size = config.sample_size,\n",
    "        #                               sample_rate = config.sample_rate,\n",
    "        #                               in_channels= config.in_channels,\n",
    "        #                               batch_size = 1)\n",
    "\n",
    "        dataset = WavenetDataset(dataset_file=workdir+\"/training_data.npz\",\n",
    "                      item_length=self.receptive_fields + self.output_length,\n",
    "                      target_length=self.output_length,\n",
    "                      file_location='train_samples/bach_chaconne',\n",
    "                      test_stride=500)\n",
    "        self.data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                      batch_size=1,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=0,\n",
    "                                                      pin_memory=False)\n",
    "    def run(self, epochs = 10):\n",
    "        total_steps = 0\n",
    "        for current_epoch in range(epochs):\n",
    "            for (inputs, targets) in iter(self.data_loader):\n",
    "                # Tensor[batch, timestep, channels]\n",
    "                inputs = inputs.transpose(1, 2).contiguous()\n",
    "                outputs = self.net(inputs)\n",
    "                print(inputs.shape, outputs.shape, targets.shape)\n",
    "                loss = self.loss(outputs.view(-1, self.in_channels),\n",
    "                                targets.long().view(-1))\n",
    "    \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_steps += 1\n",
    "    \n",
    "                print('[{0}/{1}] loss: {2}'.format(total_steps, self.config.num_steps, loss.item()))\n",
    "    \n",
    "                if total_steps > self.config.num_steps:\n",
    "                    break\n",
    "            if total_steps > self.config.num_steps:\n",
    "                    break\n",
    "        model_path = os.path.join(self.config.model_dir, 'wavenet_{step}.pkl'.format(step = self.config.num_steps))\n",
    "        torch.save(self.net.state_dict(), model_path)\n",
    "\n",
    "config_defaults = SimpleNamespace(\n",
    "    layer_size = 10,\n",
    "    stack_size = 5,\n",
    "    in_channels=256,\n",
    "    res_channels = 512,\n",
    "    sample_rate = 16000,\n",
    "    sample_size=100000,\n",
    "    lr = 0.0002,\n",
    "    data_dir = workdir +\"/audio_data\",\n",
    "    num_steps=100000,\n",
    "    model_dir = workdir+\"/model\",\n",
    ")\n",
    "trainer = Trainer(config_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TFMVS4BY2vPX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[1/100000] loss: 5.544831275939941\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[2/100000] loss: 5.544738292694092\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[3/100000] loss: 5.544644832611084\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[4/100000] loss: 5.544552803039551\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[5/100000] loss: 5.544456958770752\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[6/100000] loss: 5.544362545013428\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[7/100000] loss: 5.5442633628845215\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[8/100000] loss: 5.544159412384033\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[9/100000] loss: 5.5440545082092285\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[10/100000] loss: 5.543945789337158\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[11/100000] loss: 5.543833255767822\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[12/100000] loss: 5.543716907501221\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[13/100000] loss: 5.543594837188721\n",
      "torch.Size([1, 5131, 256]) torch.Size([1, 16, 256]) torch.Size([1, 1, 16])\n",
      "[14/100000] loss: 5.543467044830322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x105914f50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/hw3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 35\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader):\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# Tensor[batch, timestep, channels]\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     38\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(inputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[9], line 109\u001b[0m, in \u001b[0;36mWavenetDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end_position_in_next_file \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    108\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(file_index)\n\u001b[0;32m--> 109\u001b[0m     this_file \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    110\u001b[0m     sample \u001b[38;5;241m=\u001b[39m this_file[position_in_file:position_in_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# load from two files\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/site-packages/numpy/lib/format.py:856\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    854\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    855\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 856\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    858\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/site-packages/numpy/lib/format.py:991\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 991\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/zipfile/__init__.py:989\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 989\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/zipfile/__init__.py:1079\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1079\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hw3/lib/python3.12/zipfile/__init__.py:1004\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[0;34m(self, newdata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZvoheM17elo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
